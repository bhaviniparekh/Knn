{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The code is to handle categorical and continuous data of Adult dataset using K-nearest Neighbors. Both types of data require\n",
    "different ways of handling when used with this classifier. The continuous data is transformed into Zcore value. The categorical\n",
    "data is transformed using the scikit library OneHotEncoder into O's and 1's.In OneHotEncoder every unique value of the columns \n",
    "are transformed to feature. The row values of the original data set are now transformed into 0 and 1 values. The row in the\n",
    "new data frame as values for that column as 1 if in the original data frame the row had that is value else will have value 0. \n",
    "Thus new data frame will have as many columns as many unique column values in the original data set.\n",
    "\n",
    "Eg:-Let say a data frame has 2 columns. After OneHotEncoder is applied on the categorical column(Color), it will be transformed\n",
    "as shown below into a new data frame.\n",
    "    Color   Price                     \n",
    "    Red\t    2000\n",
    "    Green   5000\n",
    "    Yellow  9000\n",
    "    \n",
    "Color_Red    Color_Green   Color_Yellow   Price\n",
    "    1           0               0        2000\n",
    "    0           1               0        5000\n",
    "    0           0               1        9000\n",
    "\n",
    "The details of the algorithm are given below.\n",
    "\n",
    "1. Data is read into a pandas data frame. The columns having '?' are replaced with the mode of those columns. The data is then \n",
    "split into X(input) and Y(output/class).\n",
    "\n",
    "2. The X data are separated respectively into a continuous and categorical data frame.\n",
    "\n",
    "3. The categorical data is transformed into integer format using the OneHotEncoder library. The categorical X data \n",
    "   is fit and transformed on the object of OneHotEncoder. The output is an array where every unique value of the \n",
    "   column is transformed into a feature. The original rows in the array are now replaced with 0's and 1's as values.\n",
    "   \n",
    "4. Concatenate transformed categorical and continuous data. Train-test split this data into training and test data.\n",
    "\n",
    "5. Standardize the continuous column data by transforming and replacing the values with Zscore using the\n",
    "   StandardScaler library. The training data is fit and transformed on the StandardScaler object. The testing data is\n",
    "   transformed and replaced with Zscore over the same object on which the training data was fit.\n",
    "   \n",
    "6. Create an object of KNeighborsClassifier with n_split=43. Fit the training data on the object of k-nearest.\n",
    "   This to get the model ready.\n",
    "   \n",
    "7.  Run the test data over the model to get the prediction of every row. The knn object is used to predict \n",
    "    and calculate the accuracy score.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    '''\n",
    "    This function is to read data using Pandas read_csv function and convert into dataframe.\n",
    "    The '?' values of the columns are replaced with the mode value of those columns.\n",
    "    \n",
    "    Return :- \n",
    "    data :- Dataframe of adult data set\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    data=pd.read_csv('http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data',names=['Age','Workclass','FNLWGT','Education','Education-Num','Marital Status','Occupation','Relationship','Race','Sex','Capital Gain','Caplital Loss','Hrs-Per-Week','Native-Country','Sal'])\n",
    "    \n",
    "    for col in data.columns:\n",
    "\n",
    "        data[col].replace(' ?',data[col].mode()[0],inplace=True)\n",
    "        \n",
    "    data['Native-Country'].replace(' Trinadad&Tobago' ,'TrinadadTobago',inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \n",
    "    '''\n",
    "    The function is to split data into X  and Y(input and output) data.\n",
    "    \n",
    "    Argument :-\n",
    "    df :- Adult data frame.\n",
    "    \n",
    "    Return :-\n",
    "    x :- X data\n",
    "    y:- Y data\n",
    "    \n",
    "    \n",
    "    '''\n",
    "  \n",
    "    \n",
    "    x=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cont_data_split(xdata):\n",
    "    \n",
    "    '''\n",
    "    The function is to split the X data into categorical and continuous data.\n",
    "    \n",
    "    \n",
    "    Argument :- xdata\n",
    "    \n",
    "    Return :- \n",
    "    x_cat_data :- Categorical data frame.\n",
    "    x_cont_data :- Continuous data frame\n",
    "    \n",
    "      \n",
    "    '''\n",
    "        \n",
    "    #split xdata data into categorical data\n",
    "\n",
    "    x_cat_data=xdata[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "        \n",
    "    #split xdata into continuous data\n",
    "\n",
    "    x_cont_data=xdata[['Age','FNLWGT','Education-Num','Capital Gain','Caplital Loss','Hrs-Per-Week']]\n",
    "   \n",
    "    \n",
    "    return x_cat_data,x_cont_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(datatofit):\n",
    "    '''\n",
    "   The function is to convert the categorical data into integer format using the OneHotEncoder library. The categorical X data \n",
    "   is fit and transformed on the object of OneHotEncoder. The output is an array where every unique value of the \n",
    "   columns are transformed into a feature. The original rows in the array are now replaced with 0's and 1's as values.\n",
    "    \n",
    "    Argument :- \n",
    "    datatofit :-X-catogorical data\n",
    "    \n",
    "    Return :- \n",
    "    x_data_oe :-Onehot encoded catogorical data.\n",
    "    oe        :- Object of OneHotEncoder\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    oe=OneHotEncoder()\n",
    "    x_data_oe=oe.fit_transform(datatofit).toarray()\n",
    "    \n",
    "    return x_data_oe,oe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_cat_cont(xcat_ohe,xcont_data):\n",
    "    \n",
    "    '''\n",
    "    The function is to concatenate transformed categorical and continuous data. \n",
    "    \n",
    "    \n",
    "    Argument :- \n",
    "    xcat_ohe   :- onehotencoder data \n",
    "    xcont_data :-Continuous data.\n",
    "    \n",
    "    Return :- \n",
    "    concat_df :-Dataframe with both catogorical and continuous data.\n",
    "             \n",
    "    '''\n",
    "    xcat_ohe=pd.DataFrame(xcat_ohe)\n",
    "    concat_df=pd.concat([xcont_data,xcat_ohe],axis=1)\n",
    "    \n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(concat_cat_cont_df,ydata):\n",
    "    '''\n",
    "    The function is to train-test split the dataframe with transformed categorical data and continuous data.\n",
    "    \n",
    "    Argument :- \n",
    "    concat_cat_cont_df  :- Concatenated cat and cont data,\n",
    "    ydata               :- Y data\n",
    "    \n",
    "    Return :- \n",
    "    x_train:-training data\n",
    "    x_test :- Validation data\n",
    "    y_train :- Label data of training data\n",
    "    y_test :- label data of validation data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(concat_cat_cont_df,ydata,test_size=0.3,random_state=0)\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(fitdata,datatotransform):\n",
    "    \n",
    "    '''\n",
    "    The function is to standardize the continuous column data by transforming and replacing the values with Zscore using the\n",
    "    StandardScaler library. The training data is fit and transformed on the StandardScaler object. The testing data is\n",
    "    transformed and replaced with Zscore over the same object on which the training data was fit.\n",
    "    \n",
    "    Argument :- \n",
    "    fitdata  :- Training data.\n",
    "    datatotransform :- data to transform,training/testing\n",
    "    \n",
    "    Return :- \n",
    "    datatransformdf :- Transformed training/test data.\n",
    "       \n",
    "    '''\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(fitdata)\n",
    "    t_data=scaler.transform(datatotransform)\n",
    "    datatranformdf=pd.DataFrame(t_data,columns=[datatotransform.columns],index=datatotransform.index)\n",
    "    \n",
    "    return datatranformdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(datatotransform_df,y_train):\n",
    "    \n",
    "    '''\n",
    "    The function is to fit the training data on the object of KNeighborsClassifier.The n_split=43.This to get the model ready.\n",
    "    \n",
    "    Argument :- \n",
    "    datatotransform :- training data.\n",
    "    y_train         :- Y data of training\n",
    "    \n",
    "    Return :- \n",
    "    clf :- Object of Knn\n",
    "    \n",
    "    '''\n",
    "        \n",
    "    clf=KNeighborsClassifier(n_neighbors=43)\n",
    "    clf.fit(datatotransform_df,y_train)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_accuracy(clf_pred,test_transform_df,y_test):\n",
    "    \n",
    "    '''\n",
    "    The function is to run the test data over the model to get the prediction of every row. The knn object is used to predict \n",
    "    and calculate the accuracy score.\n",
    "    \n",
    "    Argument :- \n",
    "    clf_pred :-Knn object\n",
    "    test_transform_df :-Test data\n",
    "    y_test :- Y data of test.\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print(\"Test set prediction:{}\".format(clf_pred.predict(test_transform_df)))\n",
    "    print(\"Test set accuracy:{:.2f}\".format(clf_pred.score(test_transform_df,y_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the into data frame.\n",
    "df=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into X and Y data.\n",
    "xdata,ydata=preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the X data into categorical and continuous data frame.\n",
    "xcat_data,xcont_data=cat_cont_data_split(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the categorical data into integer format using OneHotEncoder.\n",
    "xcat_ohe,oe_obj=onehotencode(xcat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the transformed categorical data and continuous data.\n",
    "concat_cat_cont_df=concat_cat_cont(xcat_ohe,xcont_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split the concatenated data.\n",
    "xtrain,xtest,ytrain,ytest=train_test(concat_cat_cont_df,ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the training continuous data into Zscore value\n",
    "datatransform_df=scale_data(xtrain,xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the test continuous data into Zscore value\n",
    "test_transform_df=scale_data(xtrain,xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training model.\n",
    "clf_pred=fit_data(datatransform_df,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set prediction:[' <=50K' ' <=50K' ' <=50K' ... ' >50K' ' <=50K' ' <=50K']\n",
      "Test set accuracy:0.83\n"
     ]
    }
   ],
   "source": [
    "#Run the test data over model to get prediction for every row.Also get the accuracy score of predicted and actual Y data of test\n",
    "pred_accuracy(clf_pred,test_transform_df,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
