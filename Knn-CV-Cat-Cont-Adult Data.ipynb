{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "The code is to handle categorical and continuous data of Adult dataset using K-nearest Neighbors. A range of k-nearest is \n",
    "implemented along with k-fold cross-validation.For each value of knn, cross-validation is iterated and accuracy is calculated.\n",
    "Thus for every knn, we get an accuracy score,knn with the highest accuracy will be chosen for this data set.\n",
    "\n",
    "In cross-validation, X data is divided into training and test data. At every iteration X data\n",
    "is divided into n folds,1 fold will be test data and remaining folds will be training data depending on n_split value.\n",
    "eg if n_split=3 1 fold will be the test data and 2 folds will be training data. The iteration will continue till n_split value.\n",
    "The combination of testing and training data at each iteration will be different. This code works on handling both categorical\n",
    "and continuous data. Therefore at every iteration, both types of data will be handled differently as explained below.\n",
    "\n",
    "Both types of data require different ways of handling when used with this classifier. The continuous data is\n",
    "transformed into Zscore value. The categorical data is transformed using the scikit library LabelEncoder to integer format.\n",
    "The method to run the test data over the training model varies for both continuous and categorical data, for continuous data\n",
    "we use Euclidean Distance and for categorical we use Hamming Distance. \n",
    "\n",
    "The Euclidean distance works on the principle of the square root of the sum of the squared distance of the points from each\n",
    "other (SQUARE ROOT OF (X1-X2)**2 +(Y1-Y2)**2).Where has in Hamming distance, between two strings of equal length is the number\n",
    "of  positions at which the corresponding symbols are different.\n",
    "\n",
    "\n",
    "Finally, both the distances are added to get the k-nearest(k-nearest in this code is implemented manually,3 smallest distance)\n",
    "and mode of k-nearest as the final prediction. The accuracy score is calculated with predicted and actual Y data.\n",
    "\n",
    "Details of the algorithm are given below.\n",
    "\n",
    "Data is read into a pandas data frame. The columns having '?' are replaced with the mode of those columns. The data is then \n",
    "split into X(input) and Y(output/class). The code implements k-fold cross-validation.The kfold object is created with\n",
    "n_split=3. For every value of knn, kfold is iterated till n_split=3. At every iteration, the X data is divided into test and \n",
    "training data(as explained above). The test and training data are handled as give below to give final accuracy scores for a\n",
    "range of knn values:-\n",
    "\n",
    "\n",
    "1. The training and testing data are separated respectively into a continuous and categorical data frame.\n",
    "\n",
    "2. For continuous data, for every column of training data std and mean is calculated and stored in a dictionary. This data is\n",
    "used to transform training data columns to zcore value. The continuous data of testing data is transformed on std and mean of\n",
    "training data.\n",
    "\n",
    "3. For categorical data, training data is passed over the object of LabelEncoder.The data is fit to get the labels of the column\n",
    "The data is then transformed using these labels. The categorical data of testing data is also transformed on the labels of\n",
    "training data.\n",
    "In case if there are labels in the test which are not available in training, in that case, we should fit the training data \n",
    "based on the unique values of columns of the complete data set.\n",
    "\n",
    "4. Once both training and test are transformed we now calculate the distance of a row of testing data with all rows of training\n",
    "data.\n",
    "\n",
    "For continuous data, we use the Euclidean Distance metric and for categorical data,\n",
    "we use the Hamming Distance metric. Both the distance data are stored in 2 different numpy arrays.\n",
    "\n",
    "5. We need 1 value to predict, therefore, we add the values of the rows of continuous and categorical distance array's. The new\n",
    "array is now iterated row-wise using map(). Each row is converted into series with index value = Y train index. From this series\n",
    "we find the k-nearest, which is the value of knn for which these steps are executed. From the k-nearest, we find the mode. \n",
    "The corresponding mode location in the series and Y-train are matched. The label at this matching index in Y train is the \n",
    "prediction for that row.\n",
    "Incrementally at every n_split, the prediction is populated into a list to get a cumulative prediction.\n",
    "\n",
    "6. The final populated list of test predictions and actual Y data are used to calculate the accuracy score.\n",
    "\n",
    "7. The above 1-6 steps are repeated for every knn value. An accuracy score against each knn is stored in a dictionary.\n",
    "\n",
    "8. Knn with the highest accuracy is the best knn for this data.\n",
    "9. Graphically represent the knn range and respective accuracy score.\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    '''\n",
    "    This function is to read data using Pandas read_csv function and convert into dataframe.\n",
    "    The '?' values of the columns are replaced with the mode value of those columns.\n",
    "    \n",
    "    Return :- \n",
    "    data :- Dataframe of adult data set\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    data=pd.read_csv('http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data',names=['Age','Workclass','FNLWGT','Education','Education-Num','Marital Status','Occupation','Relationship','Race','Sex','Capital Gain','Caplital Loss','Hrs-Per-Week','Native-Country','Sal'])\n",
    "    for col in data.columns:\n",
    "\n",
    "        data[col].replace(' ?',data[col].mode()[0],inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data(df):\n",
    "    \n",
    "    '''\n",
    "    The function is to split data first into the Input (X) and Output (Y) dataset. \n",
    "    Argument :-\n",
    "    df :- Adult data frame\n",
    "    \n",
    "    Return :- \n",
    "    x:-training data\n",
    "    y :- Validation data\n",
    "    cat_data :- Categorical columns of complete data set before split.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    cat_data=df[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "    \n",
    "    x=df.iloc[:,0:14]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    \n",
    "    return x,y,cat_data\n",
    "\n",
    "\n",
    "def kfold_split_data(kval):\n",
    "    \n",
    "    '''\n",
    "    Function is to define in how many parts complete data needs to be split. This is done as part of cross validation.\n",
    "    \n",
    "    Argument :-\n",
    "    kval :- values for n_splits.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    kf1 = KFold(n_splits=kval)\n",
    "        \n",
    "    return kf1\n",
    "\n",
    "\n",
    "\n",
    "def process_data(x_train,x_test):\n",
    "    \n",
    "    '''\n",
    "    The function is separate train and test data into categorical and continous data respectively.\n",
    "    \n",
    "    Argument:-\n",
    "    x_train :- Training data.\n",
    "    x_test  :- Testing data\n",
    " \n",
    "    \n",
    "    Return :-\n",
    "    xtrain_cat  :- Categorical data of training data set\n",
    "    xtrain_cont :- Continuous data of training data set.\n",
    "    xtest_cat :-  Categorical data of test data.\n",
    "    xtest_cont :- Continuous data of test data.\n",
    "    '''\n",
    "    # Training data is separated into categorical and continuous data\n",
    "    \n",
    "    xtrain_cat=x_train[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "    xtrain_cont=x_train[['Age','FNLWGT','Education-Num','Capital Gain','Caplital Loss','Hrs-Per-Week']]\n",
    "    \n",
    "    # Testing data is seprated categorical and continuous data\n",
    "    \n",
    "    xtest_cat=x_test[['Workclass','Education','Marital Status','Occupation','Relationship','Race','Sex','Native-Country']]\n",
    "    xtest_cont=x_test[['Age','FNLWGT','Education-Num','Capital Gain','Caplital Loss','Hrs-Per-Week']]\n",
    "    \n",
    "    \n",
    "    return xtrain_cat,xtrain_cont,xtest_cat,xtest_cont\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cont_cal_stdmean(data):\n",
    "    \n",
    "    '''\n",
    "    This function is used to  calculate std and mean of every column of training data.\n",
    "    \n",
    "    Argument :-\n",
    "    data :- traning data set\n",
    "    \n",
    "    Return :-\n",
    "    stdmean :- Dictionary holding std and mean for each column.        \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    stdmean={}\n",
    "    for col in data.columns:\n",
    "               \n",
    "        mean_data=data[col].mean()\n",
    "        stdmean.update({'Mean'+col:mean_data})\n",
    "        std_data=data[col].std()\n",
    "        stdmean.update({'Std'+col:std_data})\n",
    "        \n",
    "    return stdmean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cont_transform_data(datatotransform,std_mean):\n",
    "    \n",
    "    '''\n",
    "    This function is used to transform and replace the training column values to Zscore values using the dictionary of\n",
    "    std and mean for every column. Both training and test data transformed.Testing data are transformed upon std and mean of\n",
    "    training data.\n",
    "        \n",
    "    Argument:- \n",
    "    std_mean=Std and mean of every column of training data.\n",
    "    datatotransform=training data/testing data\n",
    "    \n",
    "    Return:\n",
    "    datatotransform=Transformed training/test data.\n",
    "    \n",
    "       \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for col in datatotransform.columns:\n",
    "        datatotransform[col]=((datatotransform[col]-std_mean['Mean'+col])/std_mean['Std'+col])\n",
    "    \n",
    "    return datatotransform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cont_distance_cal(xcont_test,xcont_train):\n",
    "    \n",
    "    '''\n",
    "    The function is used to calculate the Ecuclidean distance between training and testing data.\n",
    "    \n",
    "    Argument:-\n",
    "    xcont_test :- Continuous data of test data set\n",
    "    xcont_train :- Continuous data of training data set\n",
    "    \n",
    "    Return :-\n",
    "    contdist_arr :- Array of distance. For each row of testing, there are corresponding all rows of training as columns.\n",
    "    '''\n",
    "       \n",
    "    contdist_arr=euclidean_distances(xcont_test,xcont_train)\n",
    "    \n",
    "    return contdist_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cat_label_encode(cato_data,datatotransform):\n",
    "    \n",
    "    '''\n",
    "    The function is to convert the categorical data into integer format. The LabelEncoder method is used to generates labels\n",
    "    for every unique value of the columns. The data is transformed into these label values. The training data is fit and transformed\n",
    "    with LabelEncoder object. On the same object, the test data is also transformed.\n",
    "    \n",
    "    \n",
    "    Argument:- \n",
    "    cato_data=complete catogorical dataset\n",
    "    datatotransform=training/test data\n",
    "    \n",
    "    Return :-\n",
    "    datatotransform :- Transformed training/test data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for x in cato_data.columns:\n",
    "        \n",
    "        \n",
    "        le.fit(cato_data[x])\n",
    "        datatotransform[x]=le.transform(datatotransform[x])\n",
    "        \n",
    "    return datatotransform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cat_hamming_dist(cat_train,cat_test):\n",
    "    \n",
    "    '''\n",
    "    The function is to calculate the Hamming distance between training and testing categorical data.\n",
    "    The DistanceMetric object is created with 'hamming' as an argument.\n",
    "    Object use's pairwise function to calculate the distance of every test row with all rows of training data.\n",
    "    \n",
    "    Argument :-\n",
    "    cat_train :- Categorical data of training data set.\n",
    "    cat_test :- Categorical data of testing data set.\n",
    "    \n",
    "    Return :-\n",
    "    dist_arr :- Array of distance. For each row of testing, there are corresponding all rows of training as columns.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    dist=DistanceMetric.get_metric('hamming')\n",
    "    \n",
    "    dist_arr=dist.pairwise(cat_test,cat_train)\n",
    "       \n",
    "    \n",
    "    return dist_arr\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(distance,y_train,val):\n",
    "    \n",
    "    '''\n",
    "    Both for categorical and continous data,data was handled differently and distance was also calculated differently\n",
    "    Funtion is for row wise values concatenating both distance for categorical and continous data after individual distance calculation.\n",
    "    For each row after adding the row values,K-nearest is calculated.\n",
    "    Mode of the K-nearest is calculated and corresponding class/category(Output column) is noted.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    list_ser=pd.Series(distance,index=y_train.index.values)\n",
    "      \n",
    "    list_ser=pd.Series(list_ser).nsmallest(val)\n",
    "    ypred=y_train.loc[list_ser.keys()].mode().values.item(0)\n",
    "    \n",
    "    \n",
    "    return ypred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pred_accuracy(y_pred_final,ydata):\n",
    "    \n",
    "    '''\n",
    "    The added rows of continuous and categorical distances are passed row-wise.Each row is converted into series with \n",
    "    index value = Y train index.From this series, we find the k-nearest. From the k-nearest, we find the mode.The corresponding\n",
    "    mode location in the series and Y-train are matched. The label at this matching index in Y train is the prediction for \n",
    "    that row.k-nearest =3 is used in the code.\n",
    "    \n",
    "    Argument :-\n",
    "    total distnace :- Row containg added values of categorical and continuos distances\n",
    "    y_train     :- Y data\n",
    "    \n",
    "    Return :-\n",
    "    ypred :- Predication for every row.\n",
    "    \n",
    "    '''\n",
    "    ydata=pd.Series.as_matrix(ydata)\n",
    "    \n",
    "    y_pred_final=pd.Series.as_matrix(y_pred_final)\n",
    "    print(\"y_pred_final type and shape\",y_pred_final.shape)\n",
    "    \n",
    "    \n",
    "    score=(np.sum(y_pred_final==ydata) *100) /ydata.size\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def knn_cv_datatransform(kf,xdata,ydata,cato_data):\n",
    "    \n",
    "    '''\n",
    "    The function is to get an accuracy score for a range of Knn values. For each value of knn, cross-validation is iterated to \n",
    "    split the X data into training and test data.At each iteration 1 fold will be test data and remaining will be training data.\n",
    "    The combination of test and training data for iteration will be different. At every iteration, the categorical and continuous\n",
    "    data are handled differently. Incremental prediction for every iteration of kfold is populated in a series to get a \n",
    "    cumulative prediction of test data. The predicted data and actual Y data is used to calculate the accuracy score.\n",
    "    For each knn, these steps are repeated and an accuracy score for each knn is stored in a dictionary object.\n",
    "    \n",
    "    \n",
    "    Arguments :-\n",
    "    kf :- kfold object\n",
    "    xdata :- X data\n",
    "    ydata :- Y data\n",
    "    cato_data :- Categorical data of complete data set.\n",
    "    \n",
    "    Return :-\n",
    "    accur_score :- accuracy score\n",
    "    '''\n",
    "    y_pred_final=pd.Series([])\n",
    "    ypred_ser=pd.Series([])\n",
    "    knn_list=list(range(3,4,5))\n",
    "    accur_score={}\n",
    "    cnt=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for val in knn_list:\n",
    "        \n",
    "        res=[]\n",
    "        for train_index,test_index in kf.split(xdata):\n",
    "            \n",
    "            x_train,x_test=xdata.iloc[train_index],xdata.iloc[test_index]\n",
    "            y_train,y_test=ydata.iloc[train_index],ydata.iloc[test_index]\n",
    "            \n",
    "            # Split x_train and x_test data into Categorical and Continuous data respectively.\n",
    "            \n",
    "            xcat_train,xcont_train,xcat_test,xcont_test=process_data(x_train,x_test)            \n",
    "           \n",
    "            # Calculate std and mean of every column.\n",
    "            \n",
    "            xtrain_cont_stdmean=cont_cal_stdmean(xcont_train)\n",
    "            \n",
    "            \n",
    "             #Transform the values of existing continuous data to Zscore values.This is done for both training and testing data.\n",
    "            \n",
    "            xcont_train=cont_transform_data(xcont_train,xtrain_cont_stdmean)\n",
    "            xcont_test=cont_transform_data(xcont_test,xtrain_cont_stdmean)\n",
    "            \n",
    "            \n",
    "            #Calcualte the Euclidean Distance between training and test data\n",
    "            \n",
    "            cont_dist_arr=cont_distance_cal(xcont_test,xcont_train)\n",
    "            \n",
    "            \n",
    "            #Convert the Categorical data into frequency(integer) using LabelEncoder.\n",
    "            #This is done for training and testing data.\n",
    "            \n",
    "            xcat_train=cat_label_encode(cato_data,xcat_train)\n",
    "            xcat_test=cat_label_encode(cato_data,xcat_test)\n",
    "            \n",
    "            \n",
    "            #Calculate the hamming distance between training and test data.\n",
    "            \n",
    "            cat_dist_arr=cat_hamming_dist(xcat_train,xcat_test)\n",
    "            \n",
    "         \n",
    "            # Predict the data,add row of catogorical and continuous data.Got from above methods.\n",
    "            \n",
    "            result = map(lambda row,row1: np.add(row,row1), cat_dist_arr,cont_dist_arr)\n",
    "            total_dist=np.array(list(result))\n",
    "            y_pred=np.apply_along_axis(get_prediction,1,total_dist,y_train,val)\n",
    "        \n",
    "            \n",
    "            ypred_ser=pd.Series(y_pred,index=x_test.index.values)\n",
    "           \n",
    "            y_pred_final=y_pred_final.append(ypred_ser)\n",
    "            \n",
    "            \n",
    "            # Calculate the Accuracy score\n",
    "        \n",
    "        score=pred_accuracy(y_pred_final,ydata)\n",
    "        accur_score.update({val:score})\n",
    "            \n",
    "      \n",
    "        \n",
    "    return accur_score\n",
    "\n",
    "\n",
    "\n",
    "def max_score_knn(max_score):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    The function is to obtain the knn with maximum accuracy score.\n",
    "    \n",
    "    Argument :-\n",
    "    max_score :- dictionary holding knn values and corresponding accuracy score.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    max_v = max(zip(max_score.values(), max_score.keys()))\n",
    "    print('Multiple Knn values with CV,manually code')\n",
    "    print('Accuracy   :  ' ,max_v[0],'       ' ,'Top Knn with max accuracy      :   ',max_v[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def plot_graph(score_accuracy):\n",
    "    \n",
    "    '''\n",
    "    The function is to graphically represent the best knn and the accuracy score.\n",
    "    \n",
    "    Argument:-\n",
    "    score_accuracy :-dictionary holding knn values and corresponding accuracy score.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    plt.plot(*zip(*sorted(score_accuracy.items())))\n",
    "    plt.xlabel('Number of Neighbors')\n",
    "    plt.ylabel('Accuracy for  K')\n",
    "    plt.yscale(\"linear\")\n",
    "    plt.xticks(range(1,10))\n",
    "    plt.ylim(45,70,0.5)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read th adult data set into pandas data frame.\n",
    "df=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data frame into X ,Y and categorical data frames\n",
    "xdata,ydata,catogorical_data=split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a object of K-fold cross validation.Assign a integer value to the variable for number of n_split\n",
    "k_val=3\n",
    "kf=kfold_split_data(k_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the code with range of knn values and kfold n_splits=3.Return values is dictionary with knn values and accuracy scores\n",
    "score_accuracy=knn_cv_datatransform(kf,xdata,ydata,catogorical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 81.8156690519333}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Knn values with CV,manually code\n",
      "Accuracy   :   81.8156690519333         Top Knn with max accuracy      :    3\n"
     ]
    }
   ],
   "source": [
    "max_score_knn(score_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(score_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
